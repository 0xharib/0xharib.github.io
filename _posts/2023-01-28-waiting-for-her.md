---
layout: article
title: Waiting for Her
date: 2023-01-28 00:00:00
type: post
parent_id: '0'
published: true
password: ''
status: published
categories:
- geekery
- software
- ai
- generativeai
- nlu
- stablediffusion
- gpt3
- gpt
- llm
- psychotherapy
- mental wellness
tags: ['geekery','software', 'ai', 'generativeai','nlu','stablediffusion','gpt3','gpt','llm', 'psychotherapy', 'mental wellness']
excerpt: Explores the feasibility of Samantha from Her (2013) and dives deeper into AI in the field of psychotherapy
---

## The Intelligent Virtual Assistant (IVA)

![Virtual Assistants](https://cdn.dribbble.com/users/210436/screenshots/5802575/media/0f5ca1a937688a95b4505775e8e814dc.png?compress=1&vertical=top)

The idea of IVAs is not new. IVA adoption has grown recently owing to:
1. Speech to text / text to speech / NLU tech improving to a point where conversation interactions with a "chatbot" become possible
2. Most OSs come with an embedded IVA across Siri, Google Assistant, Bixby, Alexa or Cortana

Apart from Google Assistant though, the naming of these IVAs tempts users to anthropomorphize and ascribe agency to them which is clearly misguided.   

## Agency
I will stop here to define Agency as the ability to:

1. Think independently
2. Act on that thinking (Free Will)

IVAs as they stand today simply do not have such capabilities.

Most importantly neither does Generative AI.

## Look at what ChatGPT said when I asked...

![Chinese Room]({{ site.baseurl }}/assets/images/2023/chineseroom.png)

[The Chinese Room](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/minds-brains-and-programs/DC644B47A4299C637C89772FACC2706A) argument put forward by John Searle in 1980 best explains:  

- You don't know a word of Chinese(sic).
- You're locked up in a room with a mail slot and receive letters exclusively written in kanji.
- There is also a rule book present inside the room which you can look up and has rules for how to respond to each character or series of characters that you see with another equivalent series of kanji characters
- You blindly follow these rules to produce a series of responses which are meaningful to those outside the room

Does this mean that you understand Chinese?  
Clearly NOT.    

Well Generative AI does exactly this. Sure the rule book is "emergent" from weights in a neural network rather than explicit programming but that doesn't dint the argument in any way.   

## Analyzing Samantha

Samantha in Her (2013) displays a wide range of capabilities. Let's try to break that down into categories.

### Group 1: Objective & Achievable today
- Contacts Management
- Personal Organizer
- Proof reading content for grammar/spelling
- Calendar reminders
- Hotel reservations
- Read and Reply to emails
- Background checks on blind dates

### Group 2: Subjective & Achievable today
- Email classification as important/unimportant
- Edit / summarize content for style
- Cherry pick written content as "the best"
- Picking a present for someone

### Group 3: Achievable with Generative AI
- High quality romantic conversations
- Companionship / Pseudo therapist

### Group 4: Probably won't happen
- Interact with external agents to get content published
- "OSes going away"

## Reimagining Psychotherapy with Generative AI

Audio / Voice interactions are the mainstay of Her (2013).  

With the stigma around seeking help for mental health issues fast reducing, I would like to posit that Generative AI will help develop the next generation of psychotherapy. Huge disclaimer here that I have no medical expertise in the area of mental wellness.

### The Therapist's Apprentice

![Therapist Apprentice]({{ site.baseurl }}/assets/images/2023/aitherapist.png)

The human user seeking a therapy session interacts with an Generative AI agent who is trained to be a patient listener and to ask probing questions.  

Ideally, beyond text, the agent is trained to read the users body language, breathing patterns, heart rate, tonality and other cues.  

During the course of this session a human therapist is available in the background for escalations and can take over the interaction seamlessly at any point in time.  

At the end of each session, the agent summarizes the interaction, snips out key sections of the conversation for human therapist review.  

### Dear Diary

![AI Therapist]({{ site.baseurl }}/assets/images/2023/whisper2robot.png)

The human user has a personalized offline virtual assistant who has received training in psychotherapy.   

The human user interacts with the virtual assistant on a daily basis, not unlike the erstwhile popular habit of making a diary entry every day.   

These conversations are completely private but the virtual assistant is trained to:
- suggest reaching out to a human psychotherapist for a session when certain thresholds of distress are breached
- escalate to law enforcement / other agencies when there are suggestions of self-harm or violence   

A fully trained psychotherapist AI can be made available offline and take up less than 1 GB of hardware space. Privacy guarantees that the user is able to speak freely without reservation as opposed to a human psychotherapist who needs to first earn the user's trust.  

Only with the user's permission and when a therapist session is scheduled will conversation logs be selectively shared with a third party.  
## Possible points of failure

The cost of failure in psychotherapy can be quite high in an edge-case especially when users are experiencing thoughts of self-harm or violence which goes undetected. Regulatory approvals can be difficult to obtain.

To date, the best example of AI led psychotherapy has been [Wysa](https://wysa.com). That said I expect tech to become vastly improved and AI psychotherapists to be in widely available and inexpensive.